{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
    "from keras.applications import Xception, VGG19, InceptionV3, imagenet_utils\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from annoy import AnnoyIndex\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import skimage, matplotlib, scipy, glob, json, shears, random, six, hashlib, sys, functools, math, uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LAYER_INDEX = -2 # default index into XCeption that will determine the image vector shape\n",
    "\n",
    "# VGG16, VGG19, and ResNet take 224×224 images; InceptionV3 and Xception take 299×299 inputs\n",
    "def resize_array(arr, shape=(299,299)):\n",
    "  '''Resize an array to a new shape'''\n",
    "  im = array_to_img(arr)\n",
    "  resized = im.resize(shape)\n",
    "  return img_to_array(resized)/255.0\n",
    "\n",
    "\n",
    "def get_uuid(*args, dtype='str', max_size=sys.maxsize, right_pad=True):\n",
    "  '''Helper method that returns a random integer'''\n",
    "  if args and isinstance(args[0], six.string_types):\n",
    "    if dtype == 'int': i = str(get_int_hash(args[0]))\n",
    "    elif dtype == 'str': i = str(uuid.uuid3(uuid.NAMESPACE_URL, args[0]))\n",
    "  else:\n",
    "    if dtype == 'int': i = str(random.randint(0, max_size))\n",
    "    elif dtype == 'str': i = str(uuid.uuid1())\n",
    "  if dtype == 'int':\n",
    "    if right_pad:\n",
    "      while len(i) < len(str(max_size)): i = i + '0'\n",
    "    return int(i)\n",
    "  return i\n",
    "\n",
    "\n",
    "def get_int_hash(s):\n",
    "  '''Given a string return an integer hash of the string's content'''\n",
    "  try:\n",
    "    return int(hashlib.sha1(args[0]).hexdigest(), 16)\n",
    "  except:\n",
    "    return int(hashlib.sha1(args[0].encode('utf8')).hexdigest(), 16)\n",
    "\n",
    "  \n",
    "def get_image_vectors(img_path):\n",
    "  '''Given the path to an image, return an ndarray with shape (n_windows_in_img, 1000)'''\n",
    "  return model.fit_transform(get_image_figures(img_path))\n",
    "\n",
    "\n",
    "def fit_transform(obj, sample_layer_index=SAMPLE_LAYER_INDEX):\n",
    "  # input shape must be n_images, h, w, colors: https://keras.io/preprocessing/image/\n",
    "  if hasattr(obj, 'shape') and len(obj.shape) == 3:\n",
    "    # this is an array of a single image\n",
    "    arr = resize_array(obj, shape=(299,299))\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "  elif hasattr(obj, 'shape') and len(obj.shape) == 4:\n",
    "    # this is an array of images\n",
    "    arr = np.array([resize_array(i, shape=(299,299)) for i in obj])\n",
    "  else:\n",
    "    # this is assumed to be a single image\n",
    "    arr = img_to_array(obj.resize((299,299)))/255.0 # see SO 47697622\n",
    "  # only Xception requires preprocessing\n",
    "  arr = imagenet_utils.preprocess_input(arr)\n",
    "  # extract the ith layer from the model (here, the -1th layer, or final layer)\n",
    "  out = K.function([model.input], [model.layers[sample_layer_index].output])([arr])\n",
    "  # parse out the k dim vector (k is determined by the size of the layer that's sampled from)\n",
    "  vec = out[0]\n",
    "  # return the vector to the calling scope\n",
    "  return vec\n",
    "\n",
    "\n",
    "model = Xception(weights='imagenet')\n",
    "setattr(model, 'fit_transform', fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=1024)\n",
    "def load_image(path, color_mode='rgb'):\n",
    "  '''Given the path to an image return a keras image object'''\n",
    "  # nb all image loading should call this method rather than load_img\n",
    "  im = img_to_array(load_img(path, color_mode=color_mode))/255.0\n",
    "  if color_mode == 'grayscale':\n",
    "    _im = im.squeeze()\n",
    "    _im = np.zeros((_im.shape[0], _im.shape[1], 3))\n",
    "    # replicate identical color information across all channels\n",
    "    _im[:,:,0] = im\n",
    "    _im[:,:,1] = im\n",
    "    if len(im.shape == 3): _im[:,:,2] = im\n",
    "    im = _im\n",
    "  im = resize_image(im)\n",
    "  return im\n",
    "\n",
    "def resize_image(im, width=1024):\n",
    "  '''Given an image array, resize that image to a target width while maintaining aspect ratio'''\n",
    "  h,w = im.shape[:2]\n",
    "  height = h/w*width\n",
    "  resized = img_to_array( array_to_img(im).resize( (int(width), int(height) )) )/255.0\n",
    "  return resized\n",
    "  \n",
    "def clean_image(im):\n",
    "  '''Given an image array return an image array that has standard width and non-significant pixels removed'''\n",
    "  im = resize_image(im)\n",
    "  _im = shears.remove_dominant_colors(im, mask_size=0.05, n_colors_to_remove=2)\n",
    "  _im = shears.filter_img(_im, min_size=1200, connectivity=60) # binarized mask-like\n",
    "  # create a mask from the remaining dark pixels in _im\n",
    "  im[np.where(_im==1)] = 1\n",
    "  return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Partitioning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=1024)\n",
    "def get_image_windows(img_path, color_mode='rgb'):\n",
    "  '''Given the path to an image, return an array of the image windows within that image'''\n",
    "  img = load_image(img_path, color_mode=color_mode)\n",
    "  arr = img_to_array(img)/255.0\n",
    "  return get_figures(arr)\n",
    "\n",
    "@functools.lru_cache(maxsize=1024)\n",
    "def get_windows(im, step=20, win=100, plot=False):\n",
    "  '''\n",
    "  Given a np array `im` with at least two dimensions, return windows of size (`win`, `win`).\n",
    "  To create the list of windows, remove text, binarize, then use that binarized result as a \n",
    "  mask to remove non-significant pixels from the original image. Finally, pass a sliding window\n",
    "  over the remainder. Only retain the subset of those windows that contain some minimum amount of\n",
    "  pixels in the mask.\n",
    "  '''\n",
    "  windows = []\n",
    "  dx = 0\n",
    "  dy = 0\n",
    "  for _ in range(im.shape[0]//step): # x axis pass\n",
    "    for _ in range(im.shape[1]//step): # y axis pass\n",
    "      w = im[dy:dy+win, dx:dx+win]\n",
    "      if w.shape == (win, win, 3):\n",
    "        windows.append(w)\n",
    "      if plot:\n",
    "        plt.imshow(w)\n",
    "        plt.title('{}-{}'.format(dx, dy))\n",
    "        plt.show()\n",
    "      dy += step\n",
    "    dx += step\n",
    "  return np.array(windows)\n",
    "\n",
    "@functools.lru_cache(maxsize=1024)\n",
    "def get_image_figures(img_path):\n",
    "  '''\n",
    "  Given the path to an image, return an iterable of numpy arrays, with one\n",
    "  for each \"figure\" in the image, where a figure represents a single\n",
    "  object that's figured, or represented (like a plant, or planet)\n",
    "  ''' \n",
    "  orig = resize_image(load_image(img_path)) # get image\n",
    "  gray = skimage.color.rgb2gray(orig) # grayscale\n",
    "  o = np.zeros(gray.shape) # binarize\n",
    "  o[np.where(gray>skimage.filters.threshold_otsu(gray))] = 1 # binarize\n",
    "  o = shears.filter_img(o, min_size=500, connectivity=60) # remove text\n",
    "  o = 1-o # reverse figure / ground\n",
    "  l = [] # initialize list that will hold extracted figures\n",
    "  for i in skimage.measure.regionprops(skimage.measure.label(o, connectivity=2)): # find figures\n",
    "    if i.area >= 2000:\n",
    "      y_min, x_min, y_max, x_max = i.bbox\n",
    "      # quick gut check to make sure this patch is not abnormally \n",
    "      w = x_max-x_min\n",
    "      h = y_max-y_min\n",
    "      if (w/h<0.2) or (h/w<0.2): continue\n",
    "      l.append(orig[y_min:y_max, x_min:x_max])\n",
    "  return np.array([resize_array(i) for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback, os\n",
    "\n",
    "meta_d = {} # d[guid] = {'path': 'collection': 'idx_in_collection'}\n",
    "\n",
    "img_paths = glob.glob('data/uvm-italian-herbal/images/*.jpg')\n",
    "collection = 'uvm-italian-herbal'\n",
    "\n",
    "img_paths = glob.glob('utils/voynichese/images/*.jpg')\n",
    "collection = 'voynichese'\n",
    "\n",
    "out_dir = 'npy'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "  os.makedirs(out_dir)\n",
    "\n",
    "if os.path.exists('meta_d.json'):\n",
    "  meta_d = {k: v for k,v in json.load(open('meta_d.json')).items() }\n",
    "\n",
    "for idx, i in enumerate(img_paths):\n",
    "    guid = get_uuid(i)\n",
    "    windows_path = os.path.join(out_dir, '{}-windows'.format(guid))\n",
    "    vectors_path = os.path.join(out_dir, '{}-vectors'.format(guid))\n",
    "    if not os.path.exists(windows_path + '.npy') or not os.path.exists(vectors_path + '.npy'):\n",
    "      print(' * processing image {} of {} in {}'.format(idx+1, len(img_paths), collection))\n",
    "      windows = get_image_figures(i)\n",
    "      vectors = model.fit_transform(windows)\n",
    "      np.save(windows_path, windows)\n",
    "      np.save(vectors_path, vectors)\n",
    "      meta_d[guid] = {'path': i, 'collection': collection, 'idx_in_collection': idx, 'image_type': 'complete'}\n",
    "  \n",
    "with open('meta_d.json', 'w') as out:\n",
    "  json.dump(meta_d, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Image Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_d = { k: v for k,v in json.load(open('meta_d.json')).items() }\n",
    "n_dims = 2048\n",
    "n_trees = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "insertion_idx = 0\n",
    "\n",
    "# todo quantize vectors for faster i/o\n",
    "if True:\n",
    "  t = AnnoyIndex(n_dims, 'angular')\n",
    "  for vector_path in glob.glob(os.path.join(out_dir, '*-vectors.npy')):\n",
    "    window_path = vector_path.replace('-vectors', '-windows')\n",
    "    vectors = np.load(vector_path)\n",
    "    windows = np.load(window_path)\n",
    "    # guid\n",
    "    guid = int(os.path.basename(vector_path).split('-')[0])\n",
    "    meta = meta_d[guid]\n",
    "    # process the collection - each vec in vectors is a window on the given page\n",
    "    for vec_idx, vec in enumerate(vectors):\n",
    "      sub_guid = uuid()\n",
    "      meta_d[sub_guid] = deepcopy(meta)\n",
    "      meta_d[sub_guid].update({'vec_idx': vec_idx, 'insertion_idx': insertion_idx, 'image_type': 'window'})      \n",
    "      t.add_item(insertion_idx, vec)\n",
    "      insertion_idx += 1\n",
    "\n",
    "  t.build(n_trees)\n",
    "  t.save('voynich.ann')\n",
    "  \n",
    "  with open('meta_d.json', 'w') as out: json.dump(meta_d, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(guid, min_sim=0.7, display=True, query_n=100, result_n=5):\n",
    "  '''\n",
    "  Given a GUID, find the insertion_idx for that GUID, use that idx to query the index, then return/display knn\n",
    "  @args\n",
    "    guid str: the guid for a subregion of an input image\n",
    "    min_sim float: the minimum similarity matches must possess to be returned\n",
    "    display bool: whether to show the matches graphically\n",
    "    n int: the number of matches to find and report\n",
    "  '''\n",
    "  m = meta_d[guid]\n",
    "  insertion_idx = m.get('insertion_idx', False)\n",
    "  if not insertion_idx: return [[], []]\n",
    "  knns, distances = u.get_nns_by_item(insertion_idx, query_n, include_distances=True)\n",
    "  sims = [1-i for i in distances[1:]] # slice off identity in sims and knns\n",
    "  knns = [insertion_idx_to_guid[insertion_index] for insertion_index in knns[1:]]\n",
    "  # filter the knn to those that are out of the query image's group\n",
    "  c = m['collection']\n",
    "  mask = [(meta_d[i]['collection'] != c) and (sims[idx]>=min_sim) for idx,i in enumerate(knns)] # determine subset of matches that are out of query image group\n",
    "  knns = [knns[i] for i,_ in enumerate(knns) if mask[i]]\n",
    "  sims = [sims[i] for i,_ in enumerate(sims) if mask[i]]\n",
    "  knns = knns[:result_n]\n",
    "  sims = sims[:result_n]  \n",
    "  # plot the matches if requested\n",
    "  if display and knns:\n",
    "    guids = [guid] + knns\n",
    "    sims = [''] + [round(i, 2) for i in sims]\n",
    "    labels = ['{} {}'.format(sims[idx], guid_to_title(i)) for idx, i in enumerate(guids)]\n",
    "    imgs = [guid_to_img(i) for i in guids]\n",
    "    plot_img_grid(imgs, labels=labels)\n",
    "  return [knns, sims]\n",
    "\n",
    "def plot_guid(guid, title=None):\n",
    "  '''Given a GUID plot the image represented by that GUID'''\n",
    "  window = guid_to_img(guid)\n",
    "  title = title if title else guid_to_title(guid)\n",
    "  plt.imshow(window)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "def plot_img_grid(img_list, rows=1, size_scalar=2, labels=[]):\n",
    "  '''Plot a list of images with `rows` rows'''\n",
    "  cols = math.ceil( len(img_list) / rows )\n",
    "  # initialize the plot\n",
    "  fig, axes = plt.subplots(rows, cols, figsize=(cols*size_scalar, rows*size_scalar), squeeze=False)\n",
    "  for idx, i in enumerate(img_list):\n",
    "    col = idx%cols\n",
    "    row = idx//cols\n",
    "    axes[row][col].imshow(img_list[idx])\n",
    "    if len(labels) > idx:\n",
    "      axes[row][col].set_title(labels[idx], fontsize=6.5)\n",
    "  plt.show()\n",
    "  \n",
    "def guid_to_img(guid):\n",
    "  '''Given a GUID return a numpy array with shape (n,n,3)'''\n",
    "  m = meta_d[guid]\n",
    "  windows = get_image_figures(m['path'])\n",
    "  return windows[m['vec_idx']]\n",
    "  \n",
    "def guid_to_title(guid):\n",
    "  '''Given a GUID return a title for the image'''\n",
    "  m = meta_d[guid]\n",
    "  if m.get('image_type') == 'window':\n",
    "    title = '{} {} {}'.format(m['collection'], m['idx_in_collection'], m['vec_idx'])\n",
    "  return title\n",
    "\n",
    "u = AnnoyIndex(n_dims, 'angular')\n",
    "u.load('voynich.ann')\n",
    "# flip the guid to insertion idx; -1 signifies guid is for full image so has no insertion idx\n",
    "insertion_idx_to_guid = {meta_d[k].get('insertion_idx', -1): k for k in meta_d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guids = list([i for i in meta_d if meta_d[i]['image_type'] == 'window'])\n",
    "guids = list([i for i in guids if meta_d[i]['collection'] == 'voynichese'])\n",
    "print(len(guids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guids_with_matches = []\n",
    "for idx, i in enumerate(guids):\n",
    "  knn, distances = get_knn(i, min_sim=0.8)\n",
    "  if knn:\n",
    "    print(idx, i)\n",
    "    guids_with_matches.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_d[guids[54]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
