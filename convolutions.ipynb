{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
    "from keras.applications import Xception, VGG19, InceptionV3, imagenet_utils\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from annoy import AnnoyIndex\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import glob, json, shears, random, six, hashlib, sys, functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LAYER_INDEX = -2 # default index into XCeption that will determine the image vector shape\n",
    "\n",
    "# VGG16, VGG19, and ResNet take 224×224 images; InceptionV3 and Xception take 299×299 inputs\n",
    "def resize_array(arr, shape=(299,299)):\n",
    "  '''Resize an array to a new shape'''\n",
    "  im = array_to_img(arr)\n",
    "  resized = im.resize(shape)\n",
    "  return img_to_array(resized)\n",
    "\n",
    "\n",
    "def fit_transform(obj, sample_layer_index=SAMPLE_LAYER_INDEX):\n",
    "  # input shape must be n_images, h, w, colors: https://keras.io/preprocessing/image/\n",
    "  if hasattr(obj, 'shape') and len(obj.shape) == 3:\n",
    "    # this is an array of a single image\n",
    "    arr = resize_array(obj)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "  elif hasattr(obj, 'shape') and len(obj.shape) == 4:\n",
    "    # this is an array of images\n",
    "    arr = np.array([resize_array(i) for i in obj])\n",
    "  else:\n",
    "    # this is assumed to be a single image\n",
    "    arr = img_to_array(img.resize((299,299))) # see SO 47697622\n",
    "  # only Xception requires preprocessing\n",
    "  arr = imagenet_utils.preprocess_input(arr)\n",
    "  # extract the ith layer from the model (here, the -1th layer, or final layer)\n",
    "  out = K.function([model.input], [model.layers[sample_layer_index].output])([arr])\n",
    "  # parse out the k dim vector (k is determined by the size of the layer that's sampled from)\n",
    "  vec = out[0]\n",
    "  # return the vector to the calling scope\n",
    "  return vec\n",
    "\n",
    "\n",
    "model = Xception(weights='imagenet')\n",
    "setattr(model, 'fit_transform', fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=1024)\n",
    "def load_image(path, color_mode='rgb'):\n",
    "  '''Given the path to an image return a keras image object'''\n",
    "  im = load_img(path, color_mode=color_mode)\n",
    "  if color_mode == 'rgb':\n",
    "    return im\n",
    "  elif color_mode == 'grayscale':\n",
    "    im = img_to_array(im).squeeze()\n",
    "    _im = np.zeros((im.shape[0], im.shape[1], 3))\n",
    "    # replicate identical color information across all channels\n",
    "    _im[:,:,0] = im\n",
    "    _im[:,:,1] = im\n",
    "    _im[:,:,2] = im\n",
    "    return _im\n",
    "  else:\n",
    "    raise Exception('Requested color_mode is not supported', color_mode)\n",
    "\n",
    "def clean_image(im, remove_background=False):\n",
    "  '''Given a keras image object return a keras image object that's cleaned'''\n",
    "  im = img_to_array(im)\n",
    "  if remove_background:\n",
    "    im = shears.remove_dominant_colors(im, mask_size=0.05, n_colors_to_remove=2)\n",
    "  return array_to_img(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uuid(*args, max_size=sys.maxsize, right_pad=True):\n",
    "  '''Helper method that returns a random integer'''\n",
    "  if args and isinstance(args[0], six.string_types):\n",
    "    try:\n",
    "      i = int(hashlib.sha1(args[0]).hexdigest(), 16)\n",
    "    except:\n",
    "      i = int(hashlib.sha1(args[0].encode('utf8')).hexdigest(), 16)\n",
    "  else:\n",
    "    i = random.randint(0, max_size)\n",
    "  if right_pad:\n",
    "    i = str(i)\n",
    "    while len(i) < len(str(max_size)):\n",
    "      i = i + '0'\n",
    "  return int(i)\n",
    "\n",
    "@functools.lru_cache(maxsize=1024)\n",
    "def get_image_windows(img_path, color_mode='rgb'):\n",
    "  '''Given the path to an image, return an array of the image windows within that image'''\n",
    "  img = clean_image(load_image(img_path, color_mode=color_mode))\n",
    "  arr = img_to_array(img)/255\n",
    "  return get_windows(arr)\n",
    "\n",
    "def get_windows(im, step=20, win=100, plot=False):\n",
    "  '''Given a np array `im` with at least two dimensions, return windows of len `win`'''\n",
    "  windows = []\n",
    "  dx = 0\n",
    "  dy = 0\n",
    "  for _ in range(im.shape[0]//step): # x axis pass\n",
    "    for _ in range(im.shape[1]//step): # y axis pass\n",
    "      dim = im[dy:dy+win, dx:dx+win]\n",
    "      if dim.shape == (win, win, 3):\n",
    "        windows.append(dim)\n",
    "      if plot:\n",
    "        plt.imshow(dim)\n",
    "        plt.title('{}-{}'.format(dx, dy))\n",
    "        plt.show()\n",
    "      dy += step\n",
    "    dx += step\n",
    "  return np.array(windows)\n",
    "\n",
    "def get_image_vectors(img_path):\n",
    "  '''Given the path to an image, return an ndarray with shape (n_windows_in_img, 1000)'''\n",
    "  return model.fit_transform(get_image_windows(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate feature separation given sample layer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool\n",
    "\n",
    "img_paths = glob.glob('utils/voynichese/images/*.jpg')\n",
    "im = img_paths[0]\n",
    "n = 40\n",
    "rows = int(n/10)\n",
    "columns = 10\n",
    "size_scalar = 4\n",
    "\n",
    "def process_layer_index(layer_index):\n",
    "  print(' * processing layer', layer_index)\n",
    "  # get this image'svectors\n",
    "  vectors = model.fit_transform(windows, layer_index)\n",
    "\n",
    "  fig, axes = plt.subplots(rows, columns, figsize=(columns*size_scalar,rows*size_scalar))\n",
    "  for odx, o in enumerate(vectors[:n]):\n",
    "    o = o.flatten().squeeze()\n",
    "    column = odx%columns\n",
    "    row = odx//columns\n",
    "    axes[row][column].scatter(range(len(o)), o, s=0.01)\n",
    "  plt.savefig('layer-index-{}-scatter.png'.format(layer_index))\n",
    "  plt.clf()\n",
    "  \n",
    "  # get the histogram of vector similarities\n",
    "  distances = []\n",
    "  for i, j in combinations(vectors, 2):\n",
    "    i = i.flatten().squeeze()\n",
    "    j = j.flatten().squeeze()\n",
    "    d = scipy.spatial.distance.cosine(i, j)\n",
    "    distances.append(d)\n",
    "  plt.hist(distances, bins=50)\n",
    "  plt.savefig('layer-index-{}-hist.png'.format(layer_index))\n",
    "  plt.clf()\n",
    "  \n",
    "  # find the aggregate distance of all windows\n",
    "  d = np.sum(distances)\n",
    "  print(' * aggregate distance', layer_index, d)\n",
    "  print(' * dims size', layer_index, o.shape)\n",
    "  return [len(o), d]\n",
    "  \n",
    "if False:\n",
    "  # get this image's windows\n",
    "  windows = get_image_windows(im)\n",
    "  distances = {}\n",
    "  shapes = {}\n",
    "  for i in range(1, 21, 1):\n",
    "    #i -= 20\n",
    "    try:\n",
    "      shape, distance = process_layer_index(i)\n",
    "      distances[i] = distance\n",
    "      shapes[i] = shape\n",
    "    except:\n",
    "      print(' * could not process idx', i)\n",
    "\n",
    "  with open('analysis-results.json', 'w') as out:\n",
    "    json.dump({\n",
    "      'distances': distances,\n",
    "      'shapes': shapes,\n",
    "    }, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback, os\n",
    "\n",
    "meta_d = {} # d[guid] = {'path': 'collection': 'idx_in_collection'}\n",
    "\n",
    "'''\n",
    "img_paths = glob.glob('utils/voynichese/images/*.jpg')\n",
    "collection = 'voynichese'\n",
    "'''\n",
    "\n",
    "img_paths = glob.glob('data/uvm-italian-herbal/images/*.jpg')\n",
    "collection = 'uvm-italian-herbal'\n",
    "\n",
    "color_mode = 'grayscale'\n",
    "out_dir = 'npy'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "  os.makedirs(out_dir)\n",
    "\n",
    "if os.path.exists('meta_d.json'):\n",
    "  meta_d = {int(k): v for k,v in json.load(open('meta_d.json')).items() }\n",
    "\n",
    "for idx, i in enumerate(img_paths):\n",
    "  try:\n",
    "    guid = uuid(i)\n",
    "    windows_path = os.path.join(out_dir, '{}-windows'.format(guid))\n",
    "    vectors_path = os.path.join(out_dir, '{}-vectors'.format(guid))\n",
    "    if not os.path.exists(windows_path + '.npy') or not os.path.exists(vectors_path + '.npy'):\n",
    "      print(' * processing image {} of {} in {}'.format(idx+1, len(img_paths), collection))\n",
    "      windows = get_image_windows(i, color_mode=color_mode)\n",
    "      vectors = model.fit_transform(windows)\n",
    "      np.save(windows_path, windows)\n",
    "      np.save(vectors_path, vectors)\n",
    "      meta_d[guid] = {'path': i, 'collection': collection, 'idx_in_collection': idx, 'image_type': 'complete'}\n",
    "  except Exception as exc:\n",
    "    print(' * could not parse', i, traceback.print_exc())\n",
    "    \n",
    "with open('meta_d.json', 'w') as out:\n",
    "  json.dump(meta_d, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Image Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_d = {int(k): v for k,v in json.load(open('meta_d.json')).items() }\n",
    "n_dims = 2048\n",
    "n_trees = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "insertion_idx = 0\n",
    "\n",
    "# todo quantize vectors for faster i/o\n",
    "if True:\n",
    "  t = AnnoyIndex(n_dims, 'angular')\n",
    "  for vector_path in glob.glob(os.path.join(out_dir, '*-vectors.npy')):\n",
    "    window_path = vector_path.replace('-vectors', '-windows')\n",
    "    vectors = np.load(vector_path)\n",
    "    windows = np.load(window_path)\n",
    "    # guid\n",
    "    guid = int(os.path.basename(vector_path).split('-')[0])\n",
    "    meta = meta_d[guid]\n",
    "    # process the collection - each vec in vectors is a window on the given page\n",
    "    for vec_idx, vec in enumerate(vectors):\n",
    "      sub_guid = uuid()\n",
    "      meta_d[sub_guid] = deepcopy(meta)\n",
    "      meta_d[sub_guid].update({'vec_idx': vec_idx, 'insertion_idx': insertion_idx, 'image_type': 'window'})      \n",
    "      t.add_item(insertion_idx, vec)\n",
    "      insertion_idx += 1\n",
    "\n",
    "  t.build(n_trees)\n",
    "  t.save('voynich.ann')\n",
    "  \n",
    "  with open('meta_d.json', 'w') as out: json.dump(meta_d, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(guid, display=True, n=10):\n",
    "  '''Given a GUID, find the insertion_idx for that GUID, use that idx to query the index, then return/display knn'''\n",
    "  m = meta_d[guid]\n",
    "  insertion_idx = m.get('insertion_idx', False)\n",
    "  if not insertion_idx: return False\n",
    "  knn, distances = u.get_nns_by_item(insertion_idx, n, include_distances=True)\n",
    "  knn = [insertion_idx_to_guid[insertion_idx] for insertion_idx in knn[1:]] # skip the identity similarity\n",
    "  distances = distances[1:]\n",
    "  if display:\n",
    "    guid = insertion_idx_to_guid[insertion_idx]\n",
    "    plot_guid(guid)\n",
    "    for idx, guid in enumerate(knn):\n",
    "      title = guid_to_title(guid)\n",
    "      similarity = round(1-distances[idx], 2)\n",
    "      plot_guid(guid, title='img: {}  sim: {}'.format(title, similarity))\n",
    "  return knn, distances\n",
    "\n",
    "def plot_guid(guid, title=None):\n",
    "  m = meta_d[guid]\n",
    "  windows = get_image_windows(m['path'])\n",
    "  window = windows[m['vec_idx']]\n",
    "  title = title if title else guid_to_title(guid)\n",
    "  plt.imshow(window)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "def guid_to_title(guid):\n",
    "  '''Given a GUID return a title for the image'''\n",
    "  m = meta_d[guid]\n",
    "  title = os.path.basename(m['path'])\n",
    "  if m.get('image_type') == 'window':\n",
    "    title = '{}-{}'.format(title, m['vec_idx'])\n",
    "  return title\n",
    "  \n",
    "u = AnnoyIndex(n_dims, 'angular')\n",
    "u.load('voynich.ann')\n",
    "# flip the guid to insertion idx; -1 signifies guid is for full image so has no insertion idx\n",
    "insertion_idx_to_guid = {meta_d[k].get('insertion_idx', -1): k for k in meta_d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guids = list([i for i in meta_d.keys() if meta_d[i].get('image_type', None) == 'window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(guids[21])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
